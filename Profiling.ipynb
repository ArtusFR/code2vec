{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7df31f",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99182c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "import models\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from torch_geometric.nn import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bebb78",
   "metadata": {},
   "source": [
    "# Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153093ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters\n",
    "\n",
    "SEED = 1234\n",
    "DATA_DIR = 'data'\n",
    "DATASET_PATH = 'java-small-preprocessed-code2vec/java-small'\n",
    "DATASET_NAME = 'java-small'\n",
    "EMBEDDING_DIM = 128\n",
    "DROPOUT = 0.25\n",
    "BATCH_SIZE = 128\n",
    "CHUNKS = 10\n",
    "MAX_LENGTH = 200\n",
    "LOG_EVERY = 1000 #print log of results after every LOG_EVERY batches\n",
    "N_EPOCHS = 20\n",
    "LOG_DIR = 'logs'\n",
    "SAVE_DIR = 'checkpoints'\n",
    "LOG_PATH = os.path.join(LOG_DIR, f'{DATASET_NAME}-log.txt')\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, f'{DATASET_NAME}-model.pt')\n",
    "LOAD = False #set true if you want to load model from MODEL_SAVE_PATH\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acdcb15",
   "metadata": {},
   "source": [
    "## Log func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f1e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logfunc(log):\n",
    "    with open(LOG_PATH, 'a+') as f:\n",
    "        f.write(log+'\\n')\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc034d",
   "metadata": {},
   "source": [
    "## Dir init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea7ded0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' if os.path.exists(LOG_PATH):\\n    os.remove(LOG_PATH) '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')\n",
    "\n",
    "if not os.path.isdir(f'{LOG_DIR}'):\n",
    "    os.makedirs(f'{LOG_DIR}')\n",
    "\n",
    "\"\"\" if os.path.exists(LOG_PATH):\n",
    "    os.remove(LOG_PATH) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c62c7e",
   "metadata": {},
   "source": [
    "# Seed fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f4a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb550c4",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c5517",
   "metadata": {},
   "source": [
    "## Dict des word (variables), path, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c20b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65ddeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.dict.c2v', 'rb') as file:\n",
    "    word2count = pickle.load(file)\n",
    "    path2count = pickle.load(file)\n",
    "    target2count = pickle.load(file)\n",
    "    n_training_examples = pickle.load(file)\n",
    "\n",
    "# create vocabularies, initialized with unk and pad tokens\n",
    "\n",
    "word2idx = {'<unk>': 0, '<pad>': 1}\n",
    "path2idx = {'<unk>': 0, '<pad>': 1 }\n",
    "target2idx = {'<unk>': 0, '<pad>': 1}\n",
    "\n",
    "for w in word2count.keys():\n",
    "    word2idx[w] = len(word2idx)\n",
    "\n",
    "for p in path2count.keys():\n",
    "    path2idx[p] = len(path2idx)\n",
    "\n",
    "for t in target2count.keys():\n",
    "    target2idx[t] = len(target2idx)\n",
    "\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "idx2path = {v: k for k, v in path2idx.items()}\n",
    "idx2target = {v: k for k, v in target2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f6ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75068c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199749, 507272, 807139)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2target), len(idx2word), len(idx2path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27702a61",
   "metadata": {},
   "source": [
    "## File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c208b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return [\n",
    "            (line.split(' ')[0], [t.split(',') for t in line.split(' ')[1:] if t.strip()])\n",
    "            for line in f if len(line.split(' ')) - 1 <= MAX_LENGTH\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            parts = line.strip().split(' ')\n",
    "            if len(parts) - 1 > MAX_LENGTH:\n",
    "                continue\n",
    "            \n",
    "            name = target2idx.get(parts[0], target2idx['<unk>'])\n",
    "            \n",
    "            path_contexts = [tuple(t.split(',')) for t in parts[1:] if t.strip()]\n",
    "            left, path, right = zip(*path_contexts) if path_contexts else ([], [], [])\n",
    "            \n",
    "            left_tensor = torch.tensor([word2idx.get(l, word2idx['<unk>']) for l in left], dtype=torch.long)\n",
    "            path_tensor = torch.tensor([path2idx.get(p, path2idx['<unk>']) for p in path], dtype=torch.long)\n",
    "            right_tensor = torch.tensor([word2idx.get(r, word2idx['<unk>']) for r in right], dtype=torch.long)\n",
    "\n",
    "            data.append((torch.tensor(name, dtype=torch.long), left_tensor, path_tensor, right_tensor))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3000e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = load_data(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.test.c2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0923d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = load_data(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.val.c2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b125651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_data(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.train.c2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877d8370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56165, 23505, 665115)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test), len(data_val), len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3940d597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665115"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_training_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f74d5",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f26ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(samples):\n",
    "    name_idx = torch.stack([e[0] for e in samples])\n",
    "    \n",
    "    max_length = max(len(e[1]) for e in samples)\n",
    "    \n",
    "    def pad_tensor(tensor_list, pad_value):\n",
    "        return torch.stack([torch.cat([t, torch.full((max_length - len(t),), pad_value)]) for t in tensor_list])\n",
    "\n",
    "    left_tensor = pad_tensor([e[1] for e in samples], word2idx['<pad>'])\n",
    "    path_tensor = pad_tensor([e[2] for e in samples], path2idx['<pad>'])\n",
    "    right_tensor = pad_tensor([e[3] for e in samples], word2idx['<pad>'])\n",
    "\n",
    "    return name_idx, left_tensor, path_tensor, right_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c5743f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE, collate_fn=collate_fn,\n",
    "                          pin_memory=True, shuffle=True, num_workers=0, prefetch_factor=None)\n",
    "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE, collate_fn=collate_fn, \n",
    "                         pin_memory=True, shuffle=False, num_workers=0, prefetch_factor=None)\n",
    "eval_loader = DataLoader(data_val, batch_size=BATCH_SIZE, collate_fn=collate_fn, \n",
    "                         pin_memory=True, shuffle=False, num_workers=0, prefetch_factor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae5bf286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5197, 439, 184)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader), len(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71ce7aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9aeea16efa4bd085ec012932430dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 625202, 0]\n"
     ]
    }
   ],
   "source": [
    "c = [0 for i in range(4)]\n",
    "for ts in tqdm(train_loader):\n",
    "    for j, t in enumerate(ts):\n",
    "        c[j] += t.eq(0).sum().item()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a1a75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del c, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6520f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 852233)\n"
     ]
    }
   ],
   "source": [
    "m, Ma = sys.maxsize, 0\n",
    "for v in path2count.values():\n",
    "    m, Ma = min(m,v), max(Ma,v)\n",
    "print((m, Ma))\n",
    "del m, Ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb39cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.desc = \"train\"\n",
    "test_loader.desc = \"test\"\n",
    "eval_loader.desc = \"eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe929a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable              Type              Data/Info\n",
      "-------------------------------------------------\n",
      "BATCH_SIZE            int               128\n",
      "CHUNKS                int               10\n",
      "DATASET_NAME          str               java-small\n",
      "DATASET_PATH          str               java-small-preprocessed-code2vec/java-small\n",
      "DATA_DIR              str               data\n",
      "DROPOUT               float             0.25\n",
      "DataLoader            type              <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "EMBEDDING_DIM         int               128\n",
      "F                     module            <module 'torch.nn.functio<...>orch\\\\nn\\\\functional.py'>\n",
      "LOAD                  bool              False\n",
      "LOG_DIR               str               logs\n",
      "LOG_EVERY             int               1000\n",
      "LOG_PATH              str               logs\\java-small-log.txt\n",
      "MAX_LENGTH            int               200\n",
      "MODEL_SAVE_PATH       str               checkpoints\\java-small-model.pt\n",
      "N_EPOCHS              int               20\n",
      "Pool                  method            <bound method BaseContext<...>t at 0x000002B359748F80>>\n",
      "SAVE_DIR              str               checkpoints\n",
      "SEED                  int               1234\n",
      "collate_fn            function          <function collate_fn at 0x000002B373C984A0>\n",
      "data_test             list              n=56165\n",
      "data_train            list              n=665115\n",
      "data_val              list              n=23505\n",
      "device                device            cuda\n",
      "eval_loader           DataLoader        <torch.utils.data.dataloa<...>ct at 0x000002B3651AA7E0>\n",
      "file                  BufferedReader    <_io.BufferedReader name=<...>all/java-small.dict.c2v'>\n",
      "idx2path              dict              n=807139\n",
      "idx2target            dict              n=199749\n",
      "idx2word              dict              n=507272\n",
      "j                     int               3\n",
      "load_data             function          <function load_data at 0x000002B36638BD80>\n",
      "logfunc               function          <function logfunc at 0x000002B35302A340>\n",
      "models                module            <module 'models' from 'c:<...>de\\\\code2vec\\\\models.py'>\n",
      "n_training_examples   int               665115\n",
      "nn                    module            <module 'torch.nn' from '<...>\\torch\\\\nn\\\\__init__.py'>\n",
      "optim                 module            <module 'torch.optim' fro<...>rch\\\\optim\\\\__init__.py'>\n",
      "os                    module            <module 'os' (frozen)>\n",
      "p                     str               158013566\n",
      "path2count            dict              n=807137\n",
      "path2idx              dict              n=807139\n",
      "random                module            <module 'random' from 'c:<...>aconda3\\\\Lib\\\\random.py'>\n",
      "summary               function          <function summary at 0x000002B36307A700>\n",
      "sys                   module            <module 'sys' (built-in)>\n",
      "t                     Tensor            tensor([[116998, 288308, <...>     1,      1,      1]])\n",
      "target2count          dict              n=199747\n",
      "target2idx            dict              n=199749\n",
      "test_loader           DataLoader        <torch.utils.data.dataloa<...>ct at 0x000002B364FE6AB0>\n",
      "torch                 module            <module 'torch' from 'C:\\<...>ges\\\\torch\\\\__init__.py'>\n",
      "tqdm                  type              <class 'tqdm.notebook.tqdm_notebook'>\n",
      "train_loader          DataLoader        <torch.utils.data.dataloa<...>ct at 0x000002B365286E40>\n",
      "v                     int               8\n",
      "w                     str               reversestringhello\n",
      "word2count            dict              n=507270\n",
      "word2idx              dict              n=507272\n"
     ]
    }
   ],
   "source": [
    "%whos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037fb7d",
   "metadata": {},
   "source": [
    "# Instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5957a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Code2Vec(\n",
    "    nodes_dim=      len(word2idx),      # nb de \"var\"\n",
    "    paths_dim=      len(path2idx),      # nb de path\n",
    "    embedding_dim=  EMBEDDING_DIM,      # à découpé\n",
    "    output_dim=     len(target2idx),    # nb de classe\n",
    "    dropout=        DROPOUT).to(device)\n",
    "\n",
    "if LOAD:\n",
    "    logfunc(f'Loading model from {MODEL_SAVE_PATH}')\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5d86f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "226a7bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: Code2Vec(\n",
      "  (node_embedding): Embedding(507272, 128)\n",
      "  (path_embedding): Embedding(807139, 128)\n",
      "  (out): Linear(in_features=128, out_features=199749, bias=False)\n",
      "  (do): Dropout(p=0.25, inplace=False)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logfunc(f\"Model structure: {model}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b3ada2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------------------------------+-----------------+-------------+\n",
      "| Layer                       | Input Shape                        | Output Shape    | #Param      |\n",
      "|-----------------------------+------------------------------------+-----------------+-------------|\n",
      "| Code2Vec                    | [128, 200], [128, 200], [128, 200] | [128, 199749]   | 193,861,760 |\n",
      "| ├─(node_embedding)Embedding | [128, 200]                         | [128, 200, 128] | 64,930,816  |\n",
      "| ├─(path_embedding)Embedding | [128, 200]                         | [128, 200, 128] | 103,313,792 |\n",
      "| ├─(out)Linear               | [128, 128]                         | [128, 199749]   | 25,567,872  |\n",
      "| ├─(do)Dropout               | [128, 200, 384]                    | [128, 200, 384] | --          |\n",
      "+-----------------------------+------------------------------------+-----------------+-------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    a=i\n",
    "    break\n",
    "logfunc(summary(model, *[b.to(device) for b in a][1:]))\n",
    "logfunc(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d6f51",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16ca3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dcfd9487c746fe8e4cb28f4e546e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval for {eval_loader.desc} batch:   0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                               Optimizer.step#Adam.step         1.26%       3.985ms         2.95%       9.337ms       1.867ms     386.000us         0.01%        2.286s     457.260ms           0 b         -20 b           0 b      -3.61 Gb             5  \n",
      "                                    aten::_foreach_add_         0.29%     908.300us         0.33%       1.046ms     104.580us     604.550ms        20.08%     604.650ms      60.465ms           0 b           0 b           0 b           0 b            10  \n",
      "                                    aten::_foreach_div_         0.21%     656.000us         0.21%     664.200us     132.840us     587.759ms        19.52%     587.809ms     117.562ms           0 b           0 b           0 b           0 b             5  \n",
      "                                    aten::_foreach_sqrt         0.21%     649.600us         0.25%     788.200us     157.640us     341.945ms        11.36%     341.995ms      68.399ms           0 b           0 b       3.61 Gb           0 b             5  \n",
      "                                aten::_foreach_addcdiv_         0.22%     694.000us         0.22%     700.900us     140.180us     293.804ms         9.76%     293.854ms      58.771ms           0 b           0 b           0 b           0 b             5  \n",
      "                                               aten::mm         0.27%     856.000us         0.27%     856.000us      57.067us     176.029ms         5.85%     176.029ms      11.735ms           0 b           0 b     977.98 Mb     977.98 Mb            15  \n",
      "                                   aten::_foreach_lerp_         0.15%     465.300us         0.15%     465.300us      93.060us     172.912ms         5.74%     172.912ms      34.582ms           0 b           0 b           0 b           0 b             5  \n",
      "                                aten::_foreach_addcmul_         0.17%     551.500us         0.18%     557.200us     111.440us     167.404ms         5.56%     167.490ms      33.498ms           0 b           0 b           0 b           0 b             5  \n",
      "autograd::engine::evaluate_function: EmbeddingBackwa...         0.11%     343.000us         3.00%       9.516ms     634.387us      97.000us         0.00%     156.143ms      10.410ms           0 b           0 b       2.95 Gb      -1.39 Gb            15  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        39.44%     124.915ms        86.57%     274.171ms      45.695ms      16.406ms         0.54%     144.585ms      24.098ms           0 b      -9.20 Mb           0 b           0 b             6  \n",
      "       autograd::engine::evaluate_function: MmBackward0         0.08%     238.700us         0.57%       1.811ms     362.220us      25.000us         0.00%     118.015ms      23.603ms           0 b           0 b           0 b    -487.98 Mb             5  \n",
      "                                            MmBackward0         0.12%     368.900us         0.50%       1.572ms     314.480us      94.000us         0.00%     117.990ms      23.598ms           0 b           0 b     487.98 Mb           0 b             5  \n",
      "                                    aten::_foreach_mul_         0.19%     607.700us         0.19%     615.100us     123.020us     116.613ms         3.87%     116.688ms      23.338ms           0 b           0 b           0 b           0 b             5  \n",
      "                                     EmbeddingBackward0         0.06%     176.900us         2.86%       9.062ms     604.100us      97.000us         0.00%      99.306ms       6.620ms           0 b           0 b       4.34 Gb           0 b            15  \n",
      "                               aten::embedding_backward         0.05%     151.900us         2.81%       8.885ms     592.307us     107.000us         0.00%      99.209ms       6.614ms           0 b           0 b       4.34 Gb           0 b            15  \n",
      "                         aten::embedding_dense_backward         1.51%       4.794ms         2.76%       8.733ms     582.180us      26.203ms         0.87%      99.102ms       6.607ms           0 b           0 b       4.34 Gb    -418.32 Mb            15  \n",
      "                                            aten::fill_         2.56%       8.123ms         2.56%       8.123ms       3.488us      77.837ms         2.59%      77.837ms      33.421us           0 b           0 b           0 b           0 b          2329  \n",
      "                                             aten::full        21.05%      66.664ms        25.55%      80.923ms      35.123us      65.604ms         2.18%      75.769ms      32.886us       2.17 Mb           0 b           0 b           0 b          2304  \n",
      "                                            aten::zero_         0.10%     313.600us         0.21%     661.700us      33.085us     109.000us         0.00%      72.839ms       3.642ms           0 b           0 b           0 b           0 b            20  \n",
      "                                            aten::zeros         0.11%     361.500us         0.28%     887.600us      59.173us     131.000us         0.00%      65.486ms       4.366ms           0 b           0 b       4.34 Gb           0 b            15  \n",
      "                               aten::cross_entropy_loss         0.03%      91.300us         0.19%     610.700us     122.140us      48.000us         0.00%      63.383ms      12.677ms           0 b           0 b     490.00 Mb           0 b             5  \n",
      "                                      aten::log_softmax         0.03%      83.600us         0.06%     202.800us      40.560us      46.000us         0.00%      63.181ms      12.636ms           0 b           0 b     490.00 Mb           0 b             5  \n",
      "                                     aten::_log_softmax         0.04%     112.800us         0.04%     112.800us      22.560us      63.125ms         2.10%      63.125ms      12.625ms           0 b           0 b     490.00 Mb     490.00 Mb             5  \n",
      "                                              aten::bmm         0.72%       2.265ms         0.72%       2.265ms      50.340us      61.178ms         2.03%      61.178ms       1.360ms           0 b           0 b     499.10 Mb     499.10 Mb            45  \n",
      "                                           aten::linear         0.03%      84.200us         0.14%     449.200us      89.840us      45.000us         0.00%      58.490ms      11.698ms           0 b           0 b     490.00 Mb           0 b             5  \n",
      "                                           aten::matmul         0.02%      47.900us         0.08%     247.600us      49.520us      28.000us         0.00%      58.384ms      11.677ms           0 b           0 b     490.00 Mb           0 b             5  \n",
      "                                             aten::add_         0.08%     242.900us         0.08%     242.900us       8.097us      56.790ms         1.89%      56.790ms       1.893ms           0 b           0 b           0 b           0 b            30  \n",
      "                                              aten::cat         9.85%      31.187ms        13.23%      41.888ms      17.954us      45.667ms         1.52%      52.304ms      22.419us       7.04 Mb       7.04 Mb     190.00 Mb     190.00 Mb          2333  \n",
      "      autograd::engine::evaluate_function: BmmBackward0         0.21%     665.700us         1.15%       3.631ms     242.087us      98.000us         0.00%      34.181ms       2.279ms           0 b           0 b       2.19 Mb    -496.11 Mb            15  \n",
      "autograd::engine::evaluate_function: LogSoftmaxBackw...         0.04%     122.400us         0.12%     366.800us      73.360us      26.000us         0.00%      31.338ms       6.268ms           0 b           0 b    -490.00 Mb    -977.67 Mb             5  \n",
      "                                    LogSoftmaxBackward0         0.03%     106.800us         0.08%     244.400us      48.880us      28.000us         0.00%      31.312ms       6.262ms           0 b           0 b     487.67 Mb           0 b             5  \n",
      "                       aten::_log_softmax_backward_data         0.04%     137.600us         0.04%     137.600us      27.520us      31.284ms         1.04%      31.284ms       6.257ms           0 b           0 b     487.67 Mb     487.67 Mb             5  \n",
      "                                           BmmBackward0         0.25%     777.100us         0.88%       2.791ms     186.087us     228.000us         0.01%      30.015ms       2.001ms           0 b           0 b     435.80 Mb           0 b            15  \n",
      "                                        aten::embedding         0.18%     579.800us         0.50%       1.573ms     104.873us     193.000us         0.01%      21.513ms       1.434ms           0 b           0 b     187.50 Mb           0 b            15  \n",
      "                                     aten::index_select         0.17%     527.200us         0.23%     742.800us      49.520us      21.079ms         0.70%      21.168ms       1.411ms           0 b           0 b     187.50 Mb           0 b            15  \n",
      "                                          aten::dropout         0.03%      89.100us         0.17%     534.600us     106.920us      34.000us         0.00%      13.775ms       2.755ms           0 b           0 b     234.38 Mb           0 b             5  \n",
      "                                            aten::stack         3.90%      12.343ms         8.09%      25.614ms       1.067ms       7.650ms         0.25%      13.770ms     573.750us       3.52 Mb           0 b           0 b           0 b            24  \n",
      "                                   aten::native_dropout         0.09%     275.100us         0.14%     445.500us      89.100us      13.669ms         0.45%      13.741ms       2.748ms           0 b           0 b     234.38 Mb           0 b             5  \n",
      "autograd::engine::evaluate_function: NativeDropoutBa...         0.03%      82.500us         0.17%     527.900us     105.580us      26.000us         0.00%      11.874ms       2.375ms           0 b           0 b     -49.38 Mb    -236.88 Mb             5  \n",
      "                                 NativeDropoutBackward0         0.05%     145.300us         0.14%     445.400us      89.080us      29.000us         0.00%      11.848ms       2.370ms           0 b           0 b     187.50 Mb           0 b             5  \n",
      "                          aten::native_dropout_backward         0.07%     215.500us         0.09%     300.100us      60.020us      11.773ms         0.39%      11.819ms       2.364ms           0 b           0 b     187.50 Mb           0 b             5  \n",
      "                                            aten::copy_         0.48%       1.532ms         0.48%       1.532ms      22.201us      10.766ms         0.36%      10.766ms     156.029us           0 b           0 b           0 b           0 b            69  \n",
      "autograd::engine::evaluate_function: NllLossBackward...         0.12%     375.600us         0.41%       1.290ms     257.940us      35.000us         0.00%       7.655ms       1.531ms           0 b           0 b     487.67 Mb      -2.50 Kb             5  \n",
      "                                       NllLossBackward0         0.09%     278.400us         0.29%     914.100us     182.820us      26.000us         0.00%       7.620ms       1.524ms           0 b           0 b     487.67 Mb           0 b             5  \n",
      "                                aten::nll_loss_backward         0.12%     386.000us         0.20%     635.700us     127.140us      80.000us         0.00%       7.594ms       1.519ms           0 b           0 b     487.67 Mb     487.67 Mb             5  \n",
      "                                           aten::narrow         1.57%       4.986ms         3.54%      11.217ms      22.257us       2.881ms         0.10%       6.844ms      13.579us           0 b           0 b           0 b           0 b           504  \n",
      "                                       aten::contiguous         0.03%     107.000us         0.34%       1.066ms      71.087us      84.000us         0.00%       6.268ms     417.867us           0 b           0 b     187.50 Mb           0 b            15  \n",
      "                                            aten::clone         0.10%     305.700us         0.30%     959.300us      63.953us     121.000us         0.00%       6.184ms     412.267us           0 b           0 b     187.50 Mb           0 b            15  \n",
      "                                        aten::unsqueeze         3.34%      10.576ms         3.72%      11.775ms      15.038us       4.446ms         0.15%       6.131ms       7.830us           0 b           0 b           0 b           0 b           783  \n",
      "                                            aten::empty         2.52%       7.966ms         2.52%       7.966ms       3.161us       5.717ms         0.19%       5.717ms       2.269us       2.17 Mb       2.17 Mb       5.05 Gb       5.05 Gb          2520  \n",
      "                                           aten::repeat         0.51%       1.604ms         0.91%       2.885ms     288.470us     322.000us         0.01%       4.987ms     498.700us           0 b           0 b     120.31 Mb           0 b            10  \n",
      "                                              aten::add         0.06%     174.300us         0.06%     174.300us      34.860us       4.068ms         0.14%       4.068ms     813.600us           0 b           0 b      62.50 Mb      62.50 Mb             5  \n",
      "                                            aten::slice         1.73%       5.477ms         1.97%       6.231ms      12.363us       2.795ms         0.09%       3.963ms       7.863us           0 b           0 b           0 b           0 b           504  \n",
      "                                             aten::tanh         0.04%     141.500us         0.04%     141.500us      28.300us       3.953ms         0.13%       3.953ms     790.600us           0 b           0 b      62.50 Mb      62.50 Mb             5  \n",
      "                                       aten::as_strided         0.73%       2.305ms         0.73%       2.305ms       1.593us       3.230ms         0.11%       3.230ms       2.232us           0 b           0 b           0 b           0 b          1447  \n",
      "     autograd::engine::evaluate_function: TanhBackward0         0.02%      76.900us         0.10%     327.600us      65.520us      28.000us         0.00%       2.935ms     587.000us           0 b           0 b     -62.50 Mb    -125.00 Mb             5  \n",
      "                                          TanhBackward0         0.03%      89.900us         0.08%     250.700us      50.140us      27.000us         0.00%       2.907ms     581.400us           0 b           0 b      62.50 Mb           0 b             5  \n",
      "                                    aten::tanh_backward         0.05%     160.800us         0.05%     160.800us      32.160us       2.880ms         0.10%       2.880ms     576.000us           0 b           0 b      62.50 Mb      62.50 Mb             5  \n",
      "autograd::engine::evaluate_function: RepeatBackward0...         0.06%     177.800us         0.41%       1.292ms     129.240us      54.000us         0.00%       2.248ms     224.800us           0 b           0 b    -119.37 Mb    -120.31 Mb            10  \n",
      "                                        RepeatBackward0         0.07%     219.100us         0.35%       1.115ms     111.460us      98.000us         0.00%       2.194ms     219.400us           0 b           0 b     962.50 Kb           0 b            10  \n",
      "                                              aten::sum         0.20%     637.900us         0.21%     657.300us      65.730us       1.997ms         0.07%       2.017ms     201.700us           0 b           0 b     962.50 Kb     962.50 Kb            10  \n",
      "                                               aten::to         0.05%     165.100us         0.30%     957.400us      31.913us     153.000us         0.01%       1.011ms      33.700us           0 b           0 b       2.93 Mb           0 b            30  \n",
      "                                         aten::_to_copy         0.12%     373.800us         0.25%     792.300us      39.615us     188.000us         0.01%     858.000us      42.900us           0 b           0 b       2.93 Mb           0 b            20  \n",
      "                                           aten::arange         0.20%     647.000us         0.34%       1.072ms      35.733us     367.000us         0.01%     797.000us      26.567us           0 b           0 b       5.86 Mb           0 b            30  \n",
      "                                       aten::pin_memory         0.21%     679.200us         0.86%       2.733ms     113.887us     226.000us         0.01%     633.000us      26.375us           0 b           0 b           0 b           0 b            24  \n",
      "                                       aten::empty_like         0.29%     905.800us         0.43%       1.375ms      21.152us     445.000us         0.01%     586.000us       9.015us           0 b           0 b     615.24 Mb           0 b            65  \n",
      "autograd::engine::evaluate_function: torch::autograd...         0.11%     347.800us         0.43%       1.361ms      54.456us     194.000us         0.01%     571.000us      22.840us           0 b           0 b           0 b           0 b            25  \n",
      "                                        aten::transpose         0.30%     938.100us         0.34%       1.064ms      19.340us     338.000us         0.01%     475.000us       8.636us           0 b           0 b           0 b           0 b            55  \n",
      "                                             aten::item         0.13%     412.800us         0.14%     454.500us       8.912us     320.000us         0.01%     438.000us       8.588us           0 b           0 b           0 b           0 b            51  \n",
      "                        torch::autograd::AccumulateGrad         0.08%     252.400us         0.32%       1.014ms      40.544us     154.000us         0.01%     377.000us      15.080us           0 b           0 b           0 b           0 b            25  \n",
      "                                      aten::_pin_memory         0.37%       1.174ms         0.59%       1.869ms      77.867us     236.000us         0.01%     347.000us      14.458us           0 b           0 b           0 b           0 b            24  \n",
      "                                                aten::t         0.11%     350.900us         0.26%     824.400us      32.976us     126.000us         0.00%     347.000us      13.880us           0 b           0 b           0 b           0 b            25  \n",
      "autograd::engine::evaluate_function: PermuteBackward...         0.11%     358.000us         0.27%     867.300us      57.820us     120.000us         0.00%     338.000us      22.533us           0 b           0 b           0 b           0 b            15  \n",
      "                                          aten::permute         0.19%     596.600us         0.21%     656.000us      21.867us     265.000us         0.01%     325.000us      10.833us           0 b           0 b           0 b           0 b            30  \n",
      "                                      aten::result_type         0.01%      34.100us         0.01%      34.100us       0.273us     311.000us         0.01%     311.000us       2.488us           0 b           0 b           0 b           0 b           125  \n",
      "      autograd::engine::evaluate_function: CatBackward0         0.02%      74.000us         0.24%     744.800us     148.960us      27.000us         0.00%     293.000us      58.600us           0 b           0 b           0 b           0 b             5  \n",
      "                                           CatBackward0         0.05%     153.900us         0.21%     670.800us     134.160us      59.000us         0.00%     266.000us      53.200us           0 b           0 b           0 b           0 b             5  \n",
      "                                           aten::unfold         0.10%     304.300us         0.11%     352.500us      11.750us     169.000us         0.01%     238.000us       7.933us           0 b           0 b           0 b           0 b            30  \n",
      "                                           aten::detach         0.20%     637.900us         0.24%     761.200us      30.448us     173.000us         0.01%     223.000us       8.920us           0 b           0 b           0 b           0 b            25  \n",
      "                                       PermuteBackward0         0.06%     198.200us         0.16%     509.300us      33.953us      98.000us         0.00%     218.000us      14.533us           0 b           0 b           0 b           0 b            15  \n",
      "autograd::engine::evaluate_function: SqueezeBackward...         0.04%     111.700us         0.13%     408.800us      40.880us      58.000us         0.00%     213.000us      21.300us           0 b           0 b           0 b           0 b            10  \n",
      "                                          aten::reshape         0.11%     343.300us         0.14%     443.100us      17.724us     149.000us         0.00%     201.000us       8.040us           0 b           0 b           0 b           0 b            25  \n",
      "                                             aten::view         0.08%     247.700us         0.08%     247.700us       3.393us     198.000us         0.01%     198.000us       2.712us           0 b           0 b           0 b           0 b            73  \n",
      "                                           aten::expand         0.08%     238.200us         0.10%     306.700us      15.335us     128.000us         0.00%     188.000us       9.400us           0 b           0 b           0 b           0 b            20  \n",
      "autograd::engine::evaluate_function: SoftmaxBackward...         0.03%      92.800us         0.16%     503.600us     100.720us      26.000us         0.00%     179.000us      35.800us           0 b           0 b    -500.00 Kb   -1000.00 Kb             5  \n",
      "                                        aten::expand_as         0.02%      78.900us         0.07%     206.000us      20.600us      66.000us         0.00%     164.000us      16.400us           0 b           0 b           0 b           0 b            10  \n",
      "                                       SqueezeBackward1         0.04%     119.700us         0.09%     297.100us      29.710us      63.000us         0.00%     155.000us      15.500us           0 b           0 b           0 b           0 b            10  \n",
      "                                      aten::nll_loss_nd         0.01%      42.400us         0.10%     316.600us      63.320us      27.000us         0.00%     154.000us      30.800us           0 b           0 b       5.00 Kb           0 b             5  \n",
      "                                       SoftmaxBackward0         0.02%      63.100us         0.13%     410.800us      82.160us      28.000us         0.00%     153.000us      30.600us           0 b           0 b     500.00 Kb           0 b             5  \n",
      "        autograd::engine::evaluate_function: TBackward0         0.03%      85.400us         0.09%     290.200us      58.040us      29.000us         0.00%     129.000us      25.800us           0 b           0 b           0 b           0 b             5  \n",
      "                                         aten::nll_loss         0.02%      66.900us         0.09%     274.200us      54.840us      25.000us         0.00%     127.000us      25.400us           0 b           0 b       5.00 Kb           0 b             5  \n",
      "                           aten::_softmax_backward_data         0.07%     226.200us         0.11%     347.700us      69.540us      66.000us         0.00%     125.000us      25.000us           0 b           0 b     500.00 Kb           0 b             5  \n",
      "                                        aten::ones_like         0.03%      98.600us         0.09%     273.600us      54.720us      38.000us         0.00%     122.000us      24.400us           0 b           0 b       2.50 Kb           0 b             5  \n",
      "                                          aten::softmax         0.01%      46.800us         0.07%     210.000us      42.000us      25.000us         0.00%     120.000us      24.000us           0 b           0 b     500.00 Kb           0 b             5  \n",
      "                              aten::_local_scalar_dense         0.01%      41.700us         0.01%      41.700us       0.818us     118.000us         0.00%     118.000us       2.314us           0 b           0 b           0 b           0 b            51  \n",
      "                                    aten::empty_strided         0.12%     394.100us         0.12%     394.100us       6.568us     118.000us         0.00%     118.000us       1.967us           0 b           0 b       3.84 Gb       3.84 Gb            60  \n",
      "                                          aten::squeeze         0.07%     225.100us         0.08%     255.500us      17.033us      82.000us         0.00%     113.000us       7.533us           0 b           0 b           0 b           0 b            15  \n",
      "                                 aten::nll_loss_forward         0.06%     202.800us         0.07%     207.300us      41.460us      93.000us         0.00%     102.000us      20.400us           0 b           0 b       5.00 Kb       5.00 Kb             5  \n",
      "                                             TBackward0         0.01%      45.000us         0.06%     204.800us      40.960us      37.000us         0.00%     100.000us      20.000us           0 b           0 b           0 b           0 b             5  \n",
      "                                         aten::_softmax         0.05%     163.200us         0.05%     163.200us      32.640us      95.000us         0.00%      95.000us      19.000us           0 b           0 b     500.00 Kb     500.00 Kb             5  \n",
      "autograd::engine::evaluate_function: UnsqueezeBackwa...         0.03%      82.100us         0.06%     201.800us      40.360us      30.000us         0.00%      95.000us      19.000us           0 b           0 b           0 b           0 b             5  \n",
      "                                          aten::resize_         0.07%     212.600us         0.07%     212.600us       6.074us      78.000us         0.00%      78.000us       2.229us           0 b           0 b     190.43 Mb     190.43 Mb            35  \n",
      "                                     UnsqueezeBackward0         0.01%      39.700us         0.04%     119.700us      23.940us      25.000us         0.00%      65.000us      13.000us           0 b           0 b           0 b           0 b             5  \n",
      "                                        aten::is_pinned         0.06%     185.300us         0.06%     185.300us       7.721us      60.000us         0.00%      60.000us       2.500us           0 b           0 b           0 b           0 b            24  \n",
      "                                              aten::mul         0.04%     121.500us         0.04%     121.500us      24.300us      59.000us         0.00%      59.000us      11.800us           0 b           0 b     500.00 Kb     500.00 Kb             5  \n",
      "                                          aten::detach_         0.01%      41.200us         0.02%      48.400us       9.680us      44.000us         0.00%      54.000us      10.800us           0 b           0 b           0 b           0 b             5  \n",
      "                                                 detach         0.04%     123.300us         0.04%     123.300us       4.932us      50.000us         0.00%      50.000us       2.000us           0 b           0 b           0 b           0 b            25  \n",
      "                                             aten::set_         0.02%      64.000us         0.02%      64.000us       2.667us      48.000us         0.00%      48.000us       2.000us           0 b           0 b           0 b           0 b            24  \n",
      "                                            aten::alias         0.01%      20.000us         0.01%      20.000us       2.000us      18.000us         0.00%      18.000us       1.800us           0 b           0 b           0 b           0 b            10  \n",
      "                     Optimizer.zero_grad#Adam.zero_grad         0.21%     673.700us         0.21%     673.700us     134.740us      10.000us         0.00%      10.000us       2.000us           0 b           0 b      -3.61 Gb      -3.61 Gb             5  \n",
      "                                       aten::lift_fresh         0.00%       1.800us         0.00%       1.800us       0.360us      10.000us         0.00%      10.000us       2.000us           0 b           0 b           0 b           0 b             5  \n",
      "                                                detach_         0.00%       7.200us         0.00%       7.200us       1.440us      10.000us         0.00%      10.000us       2.000us           0 b           0 b           0 b           0 b             5  \n",
      "                                          aten::random_         0.01%      30.300us         0.01%      30.300us      30.300us       2.000us         0.00%       2.000us       2.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us          -8 b          -8 b    -933.43 Mb    -933.43 Mb            66  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 316.722ms\n",
      "Self CUDA time total: 3.011s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], \n",
    "             record_shapes=True, profile_memory=True) as prof:\n",
    "    \n",
    "    for i, (tensor_n, tensor_l, tensor_p, tensor_r) in enumerate(tqdm(eval_loader, desc=\"eval for {eval_loader.desc} batch\", position=1)) :\n",
    "        if i >= 5:\n",
    "            break\n",
    "        # Move tensors to GPU\n",
    "        tensor_n = tensor_n.to(device, non_blocking=True)\n",
    "        tensor_l = tensor_l.to(device, non_blocking=True)\n",
    "        tensor_p = tensor_p.to(device, non_blocking=True)\n",
    "        tensor_r = tensor_r.to(device, non_blocking=True)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        fx = model(tensor_l, tensor_p, tensor_r)\n",
    "        loss = criterion(fx, tensor_n)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prof.step()\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=-1))\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d66cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6db6e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([128]),\n",
       " torch.Size([128, 200]),\n",
       " torch.Size([128, 200]),\n",
       " torch.Size([128, 200])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in a]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
