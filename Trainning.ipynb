{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7df31f",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99182c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import models\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from torch_geometric.nn import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bebb78",
   "metadata": {},
   "source": [
    "# Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153093ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setup parameters\n",
    "\n",
    "SEED = 1234\n",
    "DATA_DIR = 'data'\n",
    "DATASET_PATH = 'java-small-preprocessed-code2vec/java-small'\n",
    "DATASET_NAME = 'java-small'\n",
    "EMBEDDING_DIM = 128\n",
    "DROPOUT = 0.25\n",
    "BATCH_SIZE = 128\n",
    "MAX_LENGTH = 200\n",
    "LOG_EVERY = 1000 #print log of results after every LOG_EVERY batches\n",
    "N_EPOCHS = 20\n",
    "START_EPOCHS = 0\n",
    "LOG_DIR = 'logs'\n",
    "SAVE_DIR = 'checkpoints'\n",
    "LOG_PATH = os.path.join(LOG_DIR, f'{DATASET_NAME}-log.txt')\n",
    "STATE_FILE = os.path.join(SAVE_DIR, f\"state_file.pth\")\n",
    "LOAD = True #set true if you want to load model from MODEL_SAVE_PATH\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acdcb15",
   "metadata": {},
   "source": [
    "## Log func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6f1e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logfunc(log):\n",
    "    with open(LOG_PATH, 'a+') as f:\n",
    "        f.write(log+'\\n')\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc034d",
   "metadata": {},
   "source": [
    "## Dir init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dea7ded0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' if os.path.exists(LOG_PATH):\\n    os.remove(LOG_PATH) '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')\n",
    "\n",
    "if not os.path.isdir(f'{LOG_DIR}'):\n",
    "    os.makedirs(f'{LOG_DIR}')\n",
    "\n",
    "\"\"\" if os.path.exists(LOG_PATH):\n",
    "    os.remove(LOG_PATH) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb550c4",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c5517",
   "metadata": {},
   "source": [
    "## Dict des word (variables), path, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c65ddeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.dict.c2v', 'rb') as file:\n",
    "    word2count = pickle.load(file)\n",
    "    path2count = pickle.load(file)\n",
    "    target2count = pickle.load(file)\n",
    "    n_training_examples = pickle.load(file)\n",
    "\n",
    "# create vocabularies, initialized with unk and pad tokens\n",
    "\n",
    "word2idx = {'<unk>': 0, '<pad>': 1}\n",
    "path2idx = {'<unk>': 0, '<pad>': 1 }\n",
    "target2idx = {'<unk>': 0, '<pad>': 1}\n",
    "\n",
    "for w in word2count.keys():\n",
    "    word2idx[w] = len(word2idx)\n",
    "\n",
    "for p in path2count.keys():\n",
    "    path2idx[p] = len(path2idx)\n",
    "\n",
    "for t in target2count.keys():\n",
    "    target2idx[t] = len(target2idx)\n",
    "\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "idx2path = {v: k for k, v in path2idx.items()}\n",
    "idx2target = {v: k for k, v in target2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5f6ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75068c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_target : 199749, nb_var : 507272, nb_path 807139\n"
     ]
    }
   ],
   "source": [
    "logfunc(f\"nb_target : {len(idx2target)}, nb_var : {len(idx2word)}, nb_path {len(idx2path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27702a61",
   "metadata": {},
   "source": [
    "## File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c208b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return [\n",
    "            (line.split(' ')[0], [t.split(',') for t in line.split(' ')[1:] if t.strip()])\n",
    "            for line in f if len(line.split(' ')) - 1 <= MAX_LENGTH\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b66ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in tqdm(f.readlines(), f\"load {file_path}\"):\n",
    "            parts = line.strip().split(' ')\n",
    "            if len(parts) - 1 > MAX_LENGTH:\n",
    "                continue\n",
    "            \n",
    "            name = target2idx.get(parts[0], target2idx['<unk>'])\n",
    "            \n",
    "            path_contexts = [tuple(t.split(',')) for t in parts[1:] if t.strip()]\n",
    "            left, path, right = zip(*path_contexts) if path_contexts else ([], [], [])\n",
    "            \n",
    "            left_tensor = torch.tensor([word2idx.get(l, word2idx['<unk>']) for l in left], dtype=torch.long)\n",
    "            path_tensor = torch.tensor([path2idx.get(p, path2idx['<unk>']) for p in path], dtype=torch.long)\n",
    "            right_tensor = torch.tensor([word2idx.get(r, word2idx['<unk>']) for r in right], dtype=torch.long)\n",
    "\n",
    "            data.append((torch.tensor(name, dtype=torch.long), left_tensor, path_tensor, right_tensor))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3000e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af9c2aee282485f9369d3a15965d134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load data/java-small-preprocessed-code2vec/java-small/java-small.test.c2v:   0%|          | 0/56165 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_test = load_data(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.test.c2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd0923d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333b6efbc5c446b8846567fab1d062fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load data/java-small-preprocessed-code2vec/java-small/java-small.val.c2v:   0%|          | 0/23505 [00:00<?, ?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_val = load_data(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.val.c2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b125651b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d235dac1cf9420a8e46a26b3cdbf88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load data/java-small-preprocessed-code2vec/java-small/java-small.train.c2v:   0%|          | 0/665115 [00:00<?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = load_data(f'{DATA_DIR}/{DATASET_PATH}/{DATASET_NAME}.train.c2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "877d8370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data_test)=56165, len(data_val)=23505, len(data_train)=665115\n"
     ]
    }
   ],
   "source": [
    "logfunc(f\"len(data_test)={len(data_test)}, len(data_val)={len(data_val)}, len(data_train)={len(data_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3940d597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665115"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_training_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f74d5",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f26ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(samples):\n",
    "    name_idx = torch.stack([e[0] for e in samples])\n",
    "    \n",
    "    max_length = max(len(e[1]) for e in samples)\n",
    "    \n",
    "    def pad_tensor(tensor_list, pad_value):\n",
    "        return torch.stack([torch.cat([t, torch.full((max_length - len(t),), pad_value)]) for t in tensor_list])\n",
    "\n",
    "    left_tensor = pad_tensor([e[1] for e in samples], word2idx['<pad>'])\n",
    "    path_tensor = pad_tensor([e[2] for e in samples], path2idx['<pad>'])\n",
    "    right_tensor = pad_tensor([e[3] for e in samples], word2idx['<pad>'])\n",
    "\n",
    "    return name_idx, left_tensor, path_tensor, right_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c5743f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE, collate_fn=collate_fn,\n",
    "                          pin_memory=True, shuffle=True, num_workers=0, prefetch_factor=None)\n",
    "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE, collate_fn=collate_fn, \n",
    "                         pin_memory=True, shuffle=False, num_workers=0, prefetch_factor=None)\n",
    "eval_loader = DataLoader(data_val, batch_size=BATCH_SIZE, collate_fn=collate_fn, \n",
    "                         pin_memory=True, shuffle=False, num_workers=0, prefetch_factor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae5bf286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5197, 439, 184)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader), len(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71ce7aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92964d820ecc4988a8cace48f2e3d107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test for 0 in train tensor:   0%|          | 0/5197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 625202, 0]\n"
     ]
    }
   ],
   "source": [
    "c = [0 for i in range(4)]\n",
    "for ts in tqdm(train_loader, \"test for 0 in train tensor\"):\n",
    "    for j, t in enumerate(ts):\n",
    "        c[j] += t.eq(0).sum().item()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a1a75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del c, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6520f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path count range : (5, 852233), mean : 130.4382007019874\n"
     ]
    }
   ],
   "source": [
    "m, Ma = sys.maxsize, 0\n",
    "for v in path2count.values():\n",
    "    m, Ma = min(m,v), max(Ma,v)\n",
    "print(f\"path count range : {(m, Ma)}, mean : {sum(path2count.values())/len(path2count.values())}\")\n",
    "del m, Ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb39cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.desc = \"train\"\n",
    "test_loader.desc = \"test\"\n",
    "eval_loader.desc = \"eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037fb7d",
   "metadata": {},
   "source": [
    "# Instanciation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274b63b",
   "metadata": {},
   "source": [
    "## Seed Fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ddbe343",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dafc78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state(filepath: str, curent_epoch: int):\n",
    "    \"\"\"Save RNG states for PyTorch, CUDA and epochs number.\"\"\"\n",
    "    states = {\n",
    "        'torch_state': torch.get_state(),\n",
    "        'torch_cuda_state': torch.cuda.get_state_all() if torch.cuda.is_available() else None,\n",
    "        'curent_epoch': curent_epoch\n",
    "    }\n",
    "    torch.save(states, filepath)\n",
    "    logfunc(f\"RNG states saved to {filepath}\")\n",
    "\n",
    "def load_state(filepath: str):\n",
    "    \"\"\"Load RNG states for PyTorch, CUDA and epochs number.\"\"\"\n",
    "    states = torch.load(filepath)\n",
    "    \n",
    "    curent_epoch=states['curent_epoch']\n",
    "    torch.set_state(states['torch_state'])\n",
    "    \n",
    "    if torch.cuda.is_available() and states['torch_cuda_state'] is not None:\n",
    "        torch.cuda.set_state_all(states['torch_cuda_state'])\n",
    "    \n",
    "    logfunc(f\"RNG states loaded from {filepath}\")\n",
    "    return curent_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5957a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Code2Vec(\n",
    "    nodes_dim=      len(word2idx),      # nb de \"var\"\n",
    "    paths_dim=      len(path2idx),      # nb de path\n",
    "    embedding_dim=  EMBEDDING_DIM,      # à découpé\n",
    "    output_dim=     len(target2idx),    # nb de classe\n",
    "    dropout=        DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55472d47",
   "metadata": {},
   "source": [
    "## weight loading, curent_epoch and rng restore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints\\java-small-01-model.pt\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    curent_epoch = load_state(STATE_FILE)\n",
    "except:\n",
    "    curent_epoch = START_EPOCHS\n",
    "\n",
    "if LOAD and (curent_epoch != START_EPOCHS):\n",
    "    MODEL_SAVE_PATH = os.path.join(SAVE_DIR, f'{DATASET_NAME}-{curent_epoch:02}-model.pt')\n",
    "\n",
    "    logfunc(f'Loading model from {MODEL_SAVE_PATH}')\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "eval_criterion = nn.CrossEntropyLoss(reduction='sum').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5d86f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "226a7bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model structure: Code2Vec(\n",
      "  (node_embedding): Embedding(507272, 128)\n",
      "  (path_embedding): Embedding(807139, 128)\n",
      "  (out): Linear(in_features=128, out_features=199749, bias=False)\n",
      "  (do): Dropout(p=0.25, inplace=False)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logfunc(f\"\\nModel structure: {model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b3ada2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------------------------------+-----------------+-------------+\n",
      "| Layer                       | Input Shape                        | Output Shape    | #Param      |\n",
      "|-----------------------------+------------------------------------+-----------------+-------------|\n",
      "| Code2Vec                    | [128, 200], [128, 200], [128, 200] | [128, 199749]   | 193,861,760 |\n",
      "| ├─(node_embedding)Embedding | [128, 200]                         | [128, 200, 128] | 64,930,816  |\n",
      "| ├─(path_embedding)Embedding | [128, 200]                         | [128, 200, 128] | 103,313,792 |\n",
      "| ├─(out)Linear               | [128, 128]                         | [128, 199749]   | 25,567,872  |\n",
      "| ├─(do)Dropout               | [128, 200, 384]                    | [128, 200, 384] | --          |\n",
      "+-----------------------------+------------------------------------+-----------------+-------------+\n",
      "shape for sumary: [torch.Size([128]), torch.Size([128, 200]), torch.Size([128, 200]), torch.Size([128, 200])]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    a=i\n",
    "    break\n",
    "logfunc(summary(model, *[b.to(device) for b in a][1:]))\n",
    "logfunc(f\"shape for sumary: {[i.shape for i in a]}\")\n",
    "logfunc(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d152f5f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37327b2",
   "metadata": {},
   "source": [
    "## métrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(fx:torch.Tensor, y:torch.Tensor):\n",
    "    \"\"\"\n",
    "    Calculate top-1 accuracy\n",
    "\n",
    "    fx = [batch size, output dim]\n",
    "     y = [batch size]\n",
    "    \"\"\"\n",
    "    pred_idxs = fx.max(1, keepdim=True)[1]\n",
    "    correct = pred_idxs.eq(y.view_as(pred_idxs)).sum()\n",
    "    acc = correct.float()/pred_idxs.shape[0]\n",
    "    return acc\n",
    "\n",
    "def calculate_f1(fx, y):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall and F1 score\n",
    "    - Takes top-1 predictions\n",
    "    - Converts to strings\n",
    "    - Splits into sub-tokens\n",
    "    - Calculates TP, FP and FN\n",
    "    - Calculates precision, recall and F1 score\n",
    "\n",
    "    fx = [batch size, output dim]\n",
    "     y = [batch size]\n",
    "    \"\"\"\n",
    "    pred_idxs = fx.max(1, keepdim=True)[1]\n",
    "    pred_names = [idx2target[i.item()] for i in pred_idxs]\n",
    "    original_names = [idx2target[i.item()] for i in y]\n",
    "    true_positive, false_positive, false_negative = 0, 0, 0\n",
    "    for p, o in zip(pred_names, original_names):\n",
    "        predicted_subtokens = p.split('|')\n",
    "        original_subtokens = o.split('|')\n",
    "        for subtok in predicted_subtokens:\n",
    "            if subtok in original_subtokens:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "        for subtok in original_subtokens:\n",
    "            if not subtok in predicted_subtokens:\n",
    "                false_negative += 1\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        precision, recall, f1 = 0, 0, 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def get_metrics(tensor_n, tensor_l, tensor_p, tensor_r, model, criterion):\n",
    "    \"\"\"\n",
    "    Takes inputs, calculates loss, accuracy and other metrics, then calculates gradients and updates parameters\n",
    "\n",
    "    if optimizer is None, then we are doing evaluation so no gradients are calculated and no parameters are updated\n",
    "    \"\"\"\n",
    "\n",
    "    fx = model(tensor_l, tensor_p, tensor_r)\n",
    "\n",
    "    loss = criterion(fx, tensor_n)\n",
    "\n",
    "    acc = calculate_accuracy(fx, tensor_n)\n",
    "    precision, recall, f1 = calculate_f1(fx, tensor_n)\n",
    "\n",
    "    return loss, acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0cdfd",
   "metadata": {},
   "source": [
    "## Eval func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model:torch.nn, eval_loader:DataLoader, criterion, device:torch.device):\n",
    "    \"\"\"\n",
    "    Evaluation loop using DataLoader.\n",
    "    Wraps computations in `torch.no_grad()` to avoid unnecessary gradient calculations.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    cuml_loss, cuml_acc = 0, 0\n",
    "    true_positive, false_positive, false_negative = 0, 0, 0\n",
    "\n",
    "    nb_ex = len(eval_loader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tensor_n, tensor_l, tensor_p, tensor_r in tqdm(eval_loader, desc=\"eval for {eval_loader.desc} batch\", position=1):\n",
    "            # Move tensors to GPU\n",
    "            tensor_n = tensor_n.to(device, non_blocking=True)\n",
    "            tensor_l = tensor_l.to(device, non_blocking=True)\n",
    "            tensor_p = tensor_p.to(device, non_blocking=True)\n",
    "            tensor_r = tensor_r.to(device, non_blocking=True)\n",
    "            if torch.cuda.is_available(): torch.cuda.synchronize(device)\n",
    "\n",
    "            fx = model(tensor_l, tensor_p, tensor_r)\n",
    "\n",
    "            cuml_loss += criterion(fx, tensor_n)\n",
    "\n",
    "            # top-1 prediction\n",
    "            pred_idxs = fx.max(1, keepdim=True)[1]\n",
    "\n",
    "            #acc = calculate_accuracy(fx, tensor_n)\n",
    "            cuml_acc += pred_idxs.eq(tensor_n.view_as(pred_idxs)).sum()\n",
    "\n",
    "            #p, r, f1 = calculate_f1(fx, tensor_n)\n",
    "            \"\"\"Calculate precision, recall and F1 score\n",
    "            - Converts to strings\n",
    "            - Splits into sub-tokens\n",
    "            - Calculates TP, FP and FN\n",
    "            - Calculates precision, recall and F1 score\"\"\"\n",
    "            pred_names = [idx2target[i.item()] for i in pred_idxs]\n",
    "            original_names = [idx2target[i.item()] for i in tensor_n]\n",
    "            for p, o in zip(pred_names, original_names):\n",
    "                predicted_subtokens = p.split('|')\n",
    "                original_subtokens = o.split('|')\n",
    "                for subtok in predicted_subtokens:\n",
    "                    if subtok in original_subtokens:\n",
    "                        true_positive += 1\n",
    "                    else:\n",
    "                        false_positive += 1\n",
    "                for subtok in original_subtokens:\n",
    "                    if not subtok in predicted_subtokens:\n",
    "                        false_negative += 1\n",
    "\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        precision, recall, f1 = 0, 0, 0\n",
    "\n",
    "    return cuml_loss / nb_ex, cuml_acc / nb_ex, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd90ca2",
   "metadata": {},
   "source": [
    "## Training func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:torch.nn, train_loader:DataLoader, criterion, device:torch.device):\n",
    "    \"\"\"\n",
    "    Training loop using DataLoader for batch streaming\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    n_batches = 0\n",
    "\n",
    "    for tensor_n, tensor_l, tensor_p, tensor_r in tqdm(train_loader, desc=\"batch - trainning\", position=1):\n",
    "        # Move tensors to GPU\n",
    "        tensor_n = tensor_n.to(device, non_blocking=True)\n",
    "        tensor_l = tensor_l.to(device, non_blocking=True)\n",
    "        tensor_p = tensor_p.to(device, non_blocking=True)\n",
    "        tensor_r = tensor_r.to(device, non_blocking=True)\n",
    "        if torch.cuda.is_available(): torch.cuda.synchronize(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "               \n",
    "        fx = model(tensor_l, tensor_p, tensor_r)\n",
    "        loss = criterion(fx, tensor_n)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        n_batches += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d5847",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1da65bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "collected = gc.collect()\n",
    "print(collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a25ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88355483fea747cba91d7712601f5ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44850f847efb497db19aa7a23c62e385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch - trainning:   0%|          | 0/5197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t| Batches: 1000 | Completion: 19.245% |\n",
      "\t| Loss: 9.027 | Acc.: 0.168 | P: 0.321 | R: 0.240 | F1: 0.274\n",
      "\t| Batches: 2000 | Completion: 38.490% |\n",
      "\t| Loss: 9.090 | Acc.: 0.174 | P: 0.332 | R: 0.244 | F1: 0.281\n",
      "\t| Batches: 3000 | Completion: 57.734% |\n",
      "\t| Loss: 9.009 | Acc.: 0.183 | P: 0.346 | R: 0.252 | F1: 0.292\n",
      "\t| Batches: 4000 | Completion: 76.979% |\n",
      "\t| Loss: 8.919 | Acc.: 0.190 | P: 0.356 | R: 0.259 | F1: 0.300\n",
      "\t| Batches: 5000 | Completion: 96.224% |\n",
      "\t| Loss: 8.814 | Acc.: 0.197 | P: 0.366 | R: 0.267 | F1: 0.308\n",
      "Epoch: 03 - Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f981f062a32f4b28a55790974476adb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval for {eval_loader.desc} batch:   0%|          | 0/439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 03 |\n",
      "| Train Loss: 8.793 | Train Precision: 0.367 | Train Recall: 0.268 | Train F1: 0.310 | Train Acc: 19.81% |\n",
      "| Val. Loss: 12.142 | Val. Precision: 0.095 | Val. Recall: 0.126 | Val. F1: 0.108 | Val. Acc: 6.10% |\n",
      "Epoch: 04 - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cf9251037947228397a605221ef0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch - trainning:   0%|          | 0/5197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(START_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, N_EPOCHS), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      4\u001b[0m     logfunc(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     train_loss, train_acc, train_p, train_r, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     logfunc(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Validation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     valid_loss, valid_acc, valid_p, valid_r, valid_f1 \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n",
      "Cell \u001b[1;32mIn[35], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m tensor_p \u001b[38;5;241m=\u001b[39m tensor_p\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m tensor_r \u001b[38;5;241m=\u001b[39m tensor_r\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\cuda\\__init__.py:985\u001b[0m, in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    983\u001b[0m _lazy_init()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(START_EPOCHS+1, N_EPOCHS+1), desc=\"epoch\", position=0):\n",
    "    logfunc(f\"Epoch: {epoch:02} - Training\")\n",
    "    train(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    logfunc(f\"Epoch: {epoch:02} - Validation - train dataset\")\n",
    "    train_loss, train_acc, train_p, train_r, train_f1 = evaluate(model, eval_loader, eval_criterion, device)\n",
    "\n",
    "    logfunc(f\"Epoch: {epoch:02} - Validation - valid dataset\")\n",
    "    valid_loss, valid_acc, valid_p, valid_r, valid_f1 = evaluate(model, eval_loader, eval_criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, f'{DATASET_NAME}-{epoch:02}-model.pt'))\n",
    "\n",
    "    save_state(STATE_FILE, epoch)\n",
    "\n",
    "    log = f\"| Epoch: {epoch:02} |\\n\"\n",
    "    log += f\"| Train Loss: {train_loss:.3f} | Train Precision: {train_p:.3f} | Train Recall: {train_r:.3f} | Train F1: {train_f1:.3f} | Train Acc: {train_acc * 100:.2f}% |\\n\"\n",
    "    log += f\"| Val. Loss: {valid_loss:.3f} | Val. Precision: {valid_p:.3f} | Val. Recall: {valid_r:.3f} | Val. F1: {valid_f1:.3f} | Val. Acc: {valid_acc * 100:.2f}% |\"\n",
    "    logfunc(log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7452ba",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba75b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfunc('Testing')\n",
    "\n",
    "# model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "test_loss, test_acc, test_p, test_r, test_f1 = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "logfunc(f'| Test Loss: {test_loss:.3f} | Test Precision: {test_p:.3f} | Test Recall: {test_r:.3f} | Test F1: {test_f1:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
